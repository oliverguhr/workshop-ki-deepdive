{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oliverguhr/htw-nlp-lecture/blob/master/assignments/transformer/nlp_2_transformer_offensive_language_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x7ywAcjTMyk"
      },
      "source": [
        "# Offensive Language Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T6cFhLiDTMyk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: datasets in /home/openai/.local/lib/python3.10/site-packages (2.19.2)\n",
            "Requirement already satisfied: transformers in /home/openai/.local/lib/python3.10/site-packages (4.41.2)\n",
            "Requirement already satisfied: accelerate in /home/openai/.local/lib/python3.10/site-packages (0.30.1)\n",
            "Requirement already satisfied: sentencepiece in /home/openai/.local/lib/python3.10/site-packages (0.2.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /home/openai/.local/lib/python3.10/site-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /home/openai/.local/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.4.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /home/openai/.local/lib/python3.10/site-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /home/openai/.local/lib/python3.10/site-packages (from datasets) (0.23.2)\n",
            "Requirement already satisfied: filelock in /home/openai/.local/lib/python3.10/site-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /home/openai/.local/lib/python3.10/site-packages (from datasets) (2024.3.1)\n",
            "Requirement already satisfied: packaging in /home/openai/.local/lib/python3.10/site-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /home/openai/.local/lib/python3.10/site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: pandas in /home/openai/.local/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/openai/.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.1 in /home/openai/.local/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /home/openai/.local/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/openai/.local/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: multiprocess in /home/openai/.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/openai/.local/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/openai/.local/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/openai/.local/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /home/openai/.local/lib/python3.10/site-packages (from accelerate) (2.3.0)\n",
            "Requirement already satisfied: psutil in /home/openai/.local/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/openai/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/openai/.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/openai/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/openai/.local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/openai/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/openai/.local/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/openai/.local/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/openai/.local/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.32.1->datasets) (1.26.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.32.1->datasets) (2020.6.20)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.1->datasets) (3.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/openai/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: sympy in /home/openai/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/openai/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/openai/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/openai/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/openai/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/openai/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: triton==2.3.0 in /home/openai/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/openai/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/openai/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/openai/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/openai/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.10.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/openai/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: networkx in /home/openai/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/openai/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/openai/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/openai/.local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/openai/.local/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers accelerate sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lqhVeVEnTMyl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "--2024-06-04 20:46:26--  https://raw.githubusercontent.com/oliverguhr/htw-nlp-lecture/master/assignments/germeval2018.training.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "--2024-06-04 20:46:26--  https://raw.githubusercontent.com/oliverguhr/htw-nlp-lecture/master/assignments/germeval2018.test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir data\n",
        "!wget -c https://raw.githubusercontent.com/oliverguhr/htw-nlp-lecture/master/assignments/germeval2018.training.txt -O data/germeval2018.train.txt\n",
        "!wget -c https://raw.githubusercontent.com/oliverguhr/htw-nlp-lecture/master/assignments/germeval2018.test.txt -O data/germeval2018.test.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ONd9nMwMTMyl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4Ca0b7_IpH1M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Jun  4 20:46:27 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.161.07             Driver Version: 535.161.07   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-PCIE-16GB           On  | 00000001:00:00.0 Off |                    0 |\n",
            "| N/A   25C    P0              24W / 250W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# check if we have a GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wCOi_UiTMyl"
      },
      "source": [
        "## Prepairing the data\n",
        "\n",
        "In the next step we have to load the data and adjust it a bit. The data is available in tab delimited csv. Pandas is a good choice for simple processing, but it could also be done with Python board tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fpvStxVhTMyl"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(\"./data/germeval2018.test.txt\", sep='\\t', header=0,encoding=\"utf-8\")\n",
        "train_df = pd.read_csv(\"./data/germeval2018.train.txt\", sep='\\t', header=0,encoding=\"utf-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H9CkOlvaTMyl"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>label2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@corinnamilborn Liebe Corinna, wir würden dich...</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>OTHER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@Martin28a Sie haben ja auch Recht. Unser Twee...</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>OTHER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@ahrens_theo fröhlicher gruß aus der schönsten...</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>OTHER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@dushanwegner Amis hätten alles und jeden gewä...</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>OTHER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@spdde kein verläßlicher Verhandlungspartner. ...</td>\n",
              "      <td>OFFENSE</td>\n",
              "      <td>INSULT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text    label  label2\n",
              "0  @corinnamilborn Liebe Corinna, wir würden dich...    OTHER   OTHER\n",
              "1  @Martin28a Sie haben ja auch Recht. Unser Twee...    OTHER   OTHER\n",
              "2  @ahrens_theo fröhlicher gruß aus der schönsten...    OTHER   OTHER\n",
              "3  @dushanwegner Amis hätten alles und jeden gewä...    OTHER   OTHER\n",
              "4  @spdde kein verläßlicher Verhandlungspartner. ...  OFFENSE  INSULT"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "W4BsXBCsTMyn"
      },
      "outputs": [],
      "source": [
        "# Since we do not need the label 2 columns, we can delete them.\n",
        "test_df.drop(columns=['label2'], inplace=True)\n",
        "train_df.drop(columns=['label2'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "q4P20Gf_TMyn"
      },
      "outputs": [],
      "source": [
        "def clean_text (text):\n",
        "    #text = text.str.lower() # lowercase\n",
        "    #text = text.str.replace(r\"\\#\",\"\") # replaces hashtags\n",
        "    #text = text.str.replace(r\"http\\S+\",\"URL\")  # remove URL addresses\n",
        "    #text = text.str.replace(r\"@\",\"\")\n",
        "    #text = text.str.replace(r\"[^A-Za-z0-9öäüÖÄÜß()!?]\", \" \")\n",
        "    #text = text.str.replace(\"\\s{2,}\", \" \")\n",
        "    return text\n",
        "\n",
        "def convert_label(label):\n",
        "    return 1 if label == \"OFFENSE\" else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "p690qluXTMyn"
      },
      "outputs": [],
      "source": [
        "train_df[\"text\"]=clean_text(train_df[\"text\"])\n",
        "test_df[\"text\"]=clean_text(test_df[\"text\"])\n",
        "train_df[\"label\"]=train_df[\"label\"].map(convert_label)\n",
        "test_df[\"label\"]=test_df[\"label\"].map(convert_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9BIixoz-TMyn"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@corinnamilborn Liebe Corinna, wir würden dich...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@Martin28a Sie haben ja auch Recht. Unser Twee...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@ahrens_theo fröhlicher gruß aus der schönsten...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@dushanwegner Amis hätten alles und jeden gewä...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@spdde kein verläßlicher Verhandlungspartner. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  @corinnamilborn Liebe Corinna, wir würden dich...      0\n",
              "1  @Martin28a Sie haben ja auch Recht. Unser Twee...      0\n",
              "2  @ahrens_theo fröhlicher gruß aus der schönsten...      0\n",
              "3  @dushanwegner Amis hätten alles und jeden gewä...      0\n",
              "4  @spdde kein verläßlicher Verhandlungspartner. ...      1"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# this is  how our data set looks now\n",
        "train_df.head() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HeE1qHXhTMyo"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1688"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_df.loc[train_df[\"label\"]==1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XYIke-q7Oqfz"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "train_df = shuffle(train_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1_tIVzLTMyo"
      },
      "source": [
        "How many datasets do we have in our Train/Valid/Test sets?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6rCCzWaJTMyo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test exampels \t 3398\n",
            "Train exampels \t 4509\n",
            "Valid exampels \t 500\n"
          ]
        }
      ],
      "source": [
        "print(f\"Test exampels \\t {len(test_df) }\")\n",
        "print(f\"Train exampels \\t {len(train_df[500:])}\")\n",
        "print(f\"Valid exampels \\t {len(train_df[:500])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObJ7KjhYDxCX"
      },
      "source": [
        "In the next step we convert the data in a format that our ml lib can use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "5zRn0t3oTMyp"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "2qt9p2yeTMyp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label', '__index_level_0__'],\n",
              "    num_rows: 5009\n",
              "})"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# What is the shape of our dataset?\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUhmAob8TMyp"
      },
      "source": [
        "## Encoding of the data \n",
        "\n",
        "We convert our texts into token that our model can process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "jxDv4WeXTMyp"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset, load_metric, list_metrics\n",
        "\n",
        "\n",
        "# try out different models :) \n",
        "\n",
        "model_checkpoint =\"distilbert-base-multilingual-cased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "ZFuavLu5UlwZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "!rm -rf ./test-offsive-language/checkpoint*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "ZkNiW-kITMyp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 74658, 42635, 32092, 18496, 42488, 10304, 53978, 10136, 47419, 10115, 119, 102], [101, 12689, 10531, 10124, 169, 11132, 49219, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo_tokens = tokenizer([\"Mehr Daten führen oftmals zu besseren Ergebnissen.\", \"And this is a second sentence\"],add_special_tokens=True, truncation=True)\n",
        "demo_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "tjSb3j1RTMyp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'Mehr',\n",
              " 'Daten',\n",
              " 'führen',\n",
              " 'oft',\n",
              " '##mals',\n",
              " 'zu',\n",
              " 'besser',\n",
              " '##en',\n",
              " 'Ergebnisse',\n",
              " '##n',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.convert_ids_to_tokens(demo_tokens['input_ids'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "2CBg2qhVTMyp"
      },
      "outputs": [],
      "source": [
        "def example_tokenizer(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True,padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "tWghamclTMyp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map:   0%|          | 0/5009 [00:00<?, ? examples/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 5009/5009 [00:00<00:00, 10008.60 examples/s]\n",
            "Map: 100%|██████████| 3398/3398 [00:00<00:00, 5326.26 examples/s]\n"
          ]
        }
      ],
      "source": [
        "encoded_train_dataset = train_dataset.map(example_tokenizer, batched=True)\n",
        "encoded_test_dataset = test_dataset.map(example_tokenizer, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhkxSIVLTMyq"
      },
      "source": [
        "## The training \\o/\n",
        "\n",
        "Now we can train our model. To do this, we need to define a number of settings (hyperparameters):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "X4DtlapiTMyq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/openai/.local/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \"test-offsive-language\",\n",
        "    evaluation_strategy = \"steps\",\n",
        "    save_strategy= \"steps\",\n",
        "    learning_rate=4e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size*4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=2,\n",
        "    eval_steps=0.2,\n",
        "    save_steps=0.2,\n",
        "    warmup_steps=50,\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    overwrite_output_dir=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    save_total_limit=2,    \n",
        "    bf16=True    \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "Rh_wjh5TKhY8"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  f1 = f1_score(labels, preds, average=\"macro\")\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {\"accuracy\": acc, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "g0v5GJXmTMyq"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=encoded_train_dataset,\n",
        "    eval_dataset=encoded_test_dataset,        \n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "y_lUSvpDTMyq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='156' max='156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [156/156 03:08, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.637100</td>\n",
              "      <td>0.635779</td>\n",
              "      <td>0.662154</td>\n",
              "      <td>0.539820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.571300</td>\n",
              "      <td>0.552119</td>\n",
              "      <td>0.722484</td>\n",
              "      <td>0.647282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.458000</td>\n",
              "      <td>0.621595</td>\n",
              "      <td>0.729253</td>\n",
              "      <td>0.629988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>0.474000</td>\n",
              "      <td>0.552303</td>\n",
              "      <td>0.745438</td>\n",
              "      <td>0.679744</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=156, training_loss=0.5110889337001703, metrics={'train_runtime': 188.6745, 'train_samples_per_second': 53.097, 'train_steps_per_second': 0.827, 'total_flos': 587903510230116.0, 'train_loss': 0.5110889337001703, 'epoch': 1.9872611464968153})"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-w-nuYI8TMyr"
      },
      "outputs": [],
      "source": [
        "#tensorboard --logdir runs\n",
        "%load_ext tensorboard\n",
        "#%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/test-offsive-language/runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv-PghAYTMyr"
      },
      "source": [
        "## Testing the model\n",
        "\n",
        "The next step is to test the model with the provided test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "jYI9LEbvTMyr"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0.6942384090366289"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = trainer.predict(encoded_test_dataset)\n",
        "result.metrics[\"test_f1\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "YiYw4kS3TMyr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[  101, 10168, 10467, 10123, 10380, 54892, 10147,   102],\n",
            "        [  101, 10168, 10467, 10123, 81754,   102,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 0, 0]])}\n",
            "tensor([[0.5488, 0.4512],\n",
            "        [0.8414, 0.1586]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0, 0])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "#trainer.prediction_step(trainer.model,tokenizer(\"das ist ein test\"),False)\n",
        "trainer.model.cpu()\n",
        "#trainer.model.num_parameters()\n",
        "encoded_texts = tokenizer([\"du bist so dumm\", \"du bist toll\"],padding=True, return_tensors=\"pt\")\n",
        "print(encoded_texts)\n",
        "logits = trainer.model(**encoded_texts)\n",
        "probabilities = torch.softmax(logits[0],dim=1)\n",
        "print(probabilities)\n",
        "class_label = torch.argmax(probabilities,dim=1)\n",
        "print(class_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylTzH9P8uu-8"
      },
      "source": [
        "How can we predict a sigle test example and how long does it take on a cpu?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "_eyM790HTMyr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18.5 ms ± 906 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "def predict(text):\n",
        "    trainer.model.cpu()\n",
        "    #trainer.model.num_parameters()\n",
        "    encoded_texts = tokenizer(text, return_tensors=\"pt\")\n",
        "    #print(encoded_texts)\n",
        "    logits = trainer.model(**encoded_texts)\n",
        "    probabilities = torch.softmax(logits[0],dim=1)\n",
        "    #print(probabilities)\n",
        "    class_label = torch.argmax(probabilities)\n",
        "    return class_label\n",
        "    #print(class_label)\n",
        "\n",
        "%timeit predict(\"du bist so toll\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsL5FUdTTMys"
      },
      "source": [
        "# Tutorial:\n",
        "\n",
        "Our results are already quite good - but we can still improve the results.  First get familiar with the notebook - change a few parameters like learning rate and number of epochs and see how they change the results. \n",
        "\n",
        "**Your task is to improve the classification score.**\n",
        "\n",
        "Here are some ideas how you can improve the score.\n",
        "\n",
        "* Test different models. The [Model Hub](https://huggingface.co/models) lists a number of German models with which you can improve the results. \n",
        "\n",
        "* About 5000 sampels in the data set are comparatively few for this problem. You may find more data sets that you can add to the current training data set.\n",
        "\n",
        "* A number of multilingual models are available in the [Model Hub](https://huggingface.co/models). These models have been trained with different languages. You could also try adding English to the German dataset to train a multilingual model. This may also be better on the German data. \n",
        "\n",
        "Data augmentation is a procedure to create new data sets by modifying existing data sets. It is important that the statement does not change (the class remains the same).\n",
        "\n",
        "* You can replace synonyms words and thus generate new data sets. An example:\n",
        "\n",
        "> \"Can you still believe all this crap?\" -> \"Can you still believe all this crap?\"\n",
        "\n",
        "* Everything is allowed here. Try translating texts from German to English and back to German. If the meaning is preserved, the result can also be used for training. A small example with Google Translate:\n",
        "\n",
        "> Deutsch: \"Kann man diesen ganzen Scheiß noch glauben?\" \n",
        "\n",
        "> Englisch: \"Can you still believe all this shit?\"\n",
        "\n",
        "> Deutsch: \"Kannst du all diese Scheiße noch glauben?\"\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "nlp-2-transformer-offensive-language-classification.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
